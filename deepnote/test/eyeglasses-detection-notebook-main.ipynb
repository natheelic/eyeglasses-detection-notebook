{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## Step 1: Import Libraries",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "a54bd8a87f644136bc9863b19674e1e4",
        "deepnote_cell_type": "text-cell-h2"
      }
    },
    {
      "cell_type": "code",
      "source": "# This is a Python blockimport os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split",
      "metadata": {
        "source_hash": "9f70265e",
        "execution_start": 1690265155991,
        "execution_millis": 8914,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "af239f59015c43bca13f7dd64ec12176",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2023-07-25 06:05:56.007003: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-07-25 06:05:56.177042: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2023-07-25 06:05:56.177083: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2023-07-25 06:05:56.223237: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2023-07-25 06:05:58.697625: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2023-07-25 06:05:58.697708: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2023-07-25 06:05:58.697717: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "## Step 2: Prepare the Dataset",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "0d3e93a89083479fb254ba9b145b5553",
        "deepnote_cell_type": "text-cell-h2"
      }
    },
    {
      "cell_type": "markdown",
      "source": "You'll need a dataset containing images labeled with \"eyeglasses\" and \"no eyeglasses.\" Make sure you have the dataset organized into separate folders for each class.",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "aa5b80f652c445d09155c6182c2b12e2",
        "deepnote_cell_type": "text-cell-p"
      }
    },
    {
      "cell_type": "code",
      "source": "!ls /work/eyeglasses-detection-notebook/deepnote/test/dataset",
      "metadata": {
        "source_hash": "4c5963b7",
        "execution_start": 1690265118151,
        "execution_millis": 891,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "766a0994903142acac5ff1156086d238",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "with_eyeglasses  without_eyeglasses\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "preprocess_data_dir = '/work/eyeglasses-detection-notebook/deepnote/test/preprocess_data'",
      "metadata": {
        "allow_embed": false,
        "source_hash": "77e3f617",
        "execution_start": 1690265454021,
        "execution_millis": 13,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "83fb60ee889e4aaa8771fcf7e906f1e5",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": "dataset_dir = '/work/eyeglasses-detection-notebook/deepnote/test/dataset'",
      "metadata": {
        "allow_embed": false,
        "source_hash": "4f8b93ac",
        "execution_start": 1690265340154,
        "execution_millis": 28,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "d4e7992c54be462392e8ada4872dc6ce",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": "print(dataset_dir)\nprint(preprocess_data_dir)",
      "metadata": {
        "source_hash": "2c9ed90f",
        "execution_start": 1690265363388,
        "execution_millis": 14,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "4b956af30bae4c0ea6a79d1556d426e8",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/work/eyeglasses-detection-notebook/deepnote/test/dataset\n/work/eyeglasses-detection-notebook/deepnote/test\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": "## Step 3: Load and Preprocess Data",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "24999c8fb56c4cb8be4f39b0ecb99ff3",
        "deepnote_cell_type": "text-cell-h2"
      }
    },
    {
      "cell_type": "code",
      "source": "# Set the path to your dataset directory\ndata_dir = dataset_dir\n\n# Define image size and batch size\nimg_width, img_height = 150, 150\nbatch_size = 32\n\n# Use ImageDataGenerator for data augmentation and normalization\ndatagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n\n# Load and preprocess training data\ntrain_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='training'\n)\n\n# Load and preprocess validation data\nvalidation_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='validation'\n)",
      "metadata": {
        "source_hash": "d464704c",
        "execution_start": 1690265169916,
        "execution_millis": 28,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "052732c2af424e2686f56bed66c438ca",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Found 240 images belonging to 2 classes.\nFound 60 images belonging to 2 classes.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": "## Step 3: Load and Preprocess Data, Export files",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "e7e11ba3d2a4446fb5626119cee4824b",
        "deepnote_cell_type": "text-cell-h2"
      }
    },
    {
      "cell_type": "code",
      "source": "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n\n# Load and preprocess training data\ntrain_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='training',\n    shuffle=False  # Set shuffle to False to maintain order\n)\n\n# Load and preprocess validation data\nvalidation_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='validation',\n    shuffle=False  # Set shuffle to False to maintain order\n)\n\n# Extract data and labels from the generators\ntrain_data = np.concatenate([train_generator.next()[0] for i in range(len(train_generator))])\ntrain_labels = np.concatenate([train_generator.next()[1] for i in range(len(train_generator))])\nval_data = np.concatenate([validation_generator.next()[0] for i in range(len(validation_generator))])\nval_labels = np.concatenate([validation_generator.next()[1] for i in range(len(validation_generator))])\n\n# Save the preprocessed data and labels to files\nnp.save(preprocess_data_dir+'/train_data.npy', train_data)\nnp.save(preprocess_data_dir+'/train_labels.npy', train_labels)\nnp.save(preprocess_data_dir+'/val_data.npy', val_data)\nnp.save(preprocess_data_dir+'/val_labels.npy', val_labels)\n",
      "metadata": {
        "source_hash": "83bdfd3c",
        "execution_start": 1690265504389,
        "execution_millis": 778,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "47255d4ff2404bd482e482435b9f2e9f",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Found 240 images belonging to 2 classes.\nFound 60 images belonging to 2 classes.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "source": "## Step 4: Build the CNN Model",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "fe04b6b5025f43a49ff9ada587e8682f",
        "deepnote_cell_type": "text-cell-h2"
      }
    },
    {
      "cell_type": "code",
      "source": "# Create the CNN model\nmodel = models.Sequential()\n\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Flatten())\n\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Display model summary\nmodel.summary()\n",
      "metadata": {
        "cell_id": "29dfa7cb03484f9b8fbd520abe6839a9",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Step 5: Train the Model",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "2d6746f5424a44d4bffaaeef6d4e8b0c",
        "deepnote_cell_type": "text-cell-h2"
      }
    },
    {
      "cell_type": "code",
      "source": "# Define the number of training and validation steps per epoch\ntrain_steps_per_epoch = train_generator.samples // batch_size\nval_steps_per_epoch = validation_generator.samples // batch_size\n\n# Set the number of training epochs\nepochs = 10\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_steps_per_epoch,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=val_steps_per_epoch\n)",
      "metadata": {
        "cell_id": "f7fd0f0b75a848439d15b81e5757442a",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Step 6: Evaluate the Model",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "0afce0d05ba1485084ae72c5fa957fd6",
        "deepnote_cell_type": "text-cell-h2"
      }
    },
    {
      "cell_type": "code",
      "source": "# Evaluate the model on the test set\nloss, accuracy = model.evaluate(validation_generator, steps=val_steps_per_epoch)\nprint(f\"Validation Accuracy: {accuracy*100:.2f}%\")",
      "metadata": {
        "source_hash": null,
        "execution_start": 1690257371196,
        "execution_millis": 435,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "dafe98721fba48458314f2a44dd64b73",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(validation_generator, steps\u001b[38;5;241m=\u001b[39mval_steps_per_epoch)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Step 7: Make Predictions",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "bfda677da3e640e09f7af25188d090e0",
        "deepnote_cell_type": "text-cell-h2"
      }
    },
    {
      "cell_type": "markdown",
      "source": "After training and evaluating the model, you can use it to make predictions on new images. Use the model.predict() function to obtain the prediction probabilities for each class. For instance:",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "089b433b94954a0e8193819b76da73c0",
        "deepnote_cell_type": "text-cell-p"
      }
    },
    {
      "cell_type": "code",
      "source": "# Assuming you have a new image (img) to predict\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Add batch dimension\n\n# Make the prediction\npredictions = model.predict(img_array)\nprobability = predictions[0][0]\n\n# Check if the image contains eyeglasses or not\nif probability > 0.5:\n    print(\"Eyeglasses detected!\")\nelse:\n    print(\"No eyeglasses detected.\")",
      "metadata": {
        "cell_id": "a295056af79a41588552671884d163da",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d822edbe-8d88-4e5f-b475-b8b674ae1c11' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote": {},
    "orig_nbformat": 2,
    "deepnote_notebook_id": "b2bab72d9a7347ceb733ca7e9a20eabf",
    "deepnote_execution_queue": [],
    "deepnote_persisted_session": {
      "createdAt": "2023-07-25T05:32:51.653Z"
    }
  }
}