{"cells":[{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"d6b5cdf3b2844ecb8981ec720322a12f","deepnote_cell_type":"text-cell-h2"},"source":"## Step 1: Import Libraries"},{"cell_type":"code","metadata":{"source_hash":"9f70265e","execution_start":1690257230268,"execution_millis":7,"deepnote_to_be_reexecuted":false,"cell_id":"77293fd509bc4f298f9630e14ea60202","deepnote_cell_type":"code"},"source":"# This is a Python blockimport os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split","execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"e8035ebcb8714315a29e40f2289d692b","deepnote_cell_type":"text-cell-h2"},"source":"## Step 2: Prepare the Dataset"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"3bb40e446ed54b029129f3666193d3e8","deepnote_cell_type":"text-cell-p"},"source":"You'll need a dataset containing images labeled with \"eyeglasses\" and \"no eyeglasses.\" Make sure you have the dataset organized into separate folders for each class."},{"cell_type":"code","metadata":{"source_hash":"e44c076f","execution_start":1690257781555,"execution_millis":1633,"deepnote_to_be_reexecuted":false,"cell_id":"06fc4c02908747c38444189b3652edba","deepnote_cell_type":"code"},"source":"!ls /datasets/licacth-drive/0000000000000_KMUTT/Build_a_Deep_CNN/dataset/","execution_count":8,"outputs":[{"name":"stdout","text":"with_eyeglasses  without_eyeglasses\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"allow_embed":false,"source_hash":"76082c19","execution_start":1690257794541,"execution_millis":8,"deepnote_to_be_reexecuted":false,"cell_id":"5c8f71e42b584f4cb004d41c9494da1f","deepnote_cell_type":"code"},"source":"dataset_dir = '/datasets/licacth-drive/0000000000000_KMUTT/Build_a_Deep_CNN/dataset/'","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":"862fe71d","execution_start":1690257801573,"execution_millis":18,"deepnote_to_be_reexecuted":false,"cell_id":"368fb6086fb84028b3663ed5857363c0","deepnote_cell_type":"code"},"source":"dataset_dir","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"'/datasets/licacth-drive/0000000000000_KMUTT/Build_a_Deep_CNN/dataset/'"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"89cc6e4fc4ac412aaac9052bb41af59f","deepnote_cell_type":"text-cell-h2"},"source":"## Step 3: Load and Preprocess Data"},{"cell_type":"code","metadata":{"source_hash":"d464704c","execution_start":1690257846652,"execution_millis":1147,"deepnote_to_be_reexecuted":false,"cell_id":"606b8da7785a4550881b7af058ba6d44","deepnote_cell_type":"code"},"source":"# Set the path to your dataset directory\ndata_dir = dataset_dir\n\n# Define image size and batch size\nimg_width, img_height = 150, 150\nbatch_size = 32\n\n# Use ImageDataGenerator for data augmentation and normalization\ndatagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n\n# Load and preprocess training data\ntrain_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='training'\n)\n\n# Load and preprocess validation data\nvalidation_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='validation'\n)","execution_count":12,"outputs":[{"name":"stdout","text":"Found 240 images belonging to 2 classes.\nFound 60 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"3481051121734ecc99b489429aff2040","deepnote_cell_type":"text-cell-h2"},"source":"## Step 3: Load and Preprocess Data, Export files"},{"cell_type":"code","metadata":{"source_hash":"76c2d1d6","execution_start":1690258020355,"execution_millis":280176,"deepnote_to_be_reexecuted":false,"cell_id":"a51e4fa1362b48ef9b503c03ac0e368c","deepnote_cell_type":"code"},"source":"datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n\n# Load and preprocess training data\ntrain_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='training',\n    shuffle=False  # Set shuffle to False to maintain order\n)\n\n# Load and preprocess validation data\nvalidation_generator = datagen.flow_from_directory(\n    data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='validation',\n    shuffle=False  # Set shuffle to False to maintain order\n)\n\n# Extract data and labels from the generators\ntrain_data = np.concatenate([train_generator.next()[0] for i in range(len(train_generator))])\ntrain_labels = np.concatenate([train_generator.next()[1] for i in range(len(train_generator))])\nval_data = np.concatenate([validation_generator.next()[0] for i in range(len(validation_generator))])\nval_labels = np.concatenate([validation_generator.next()[1] for i in range(len(validation_generator))])\n\n# Save the preprocessed data and labels to files\nnp.save('train_data.npy', train_data)\nnp.save('train_labels.npy', train_labels)\nnp.save('val_data.npy', val_data)\nnp.save('val_labels.npy', val_labels)\n","execution_count":14,"outputs":[{"name":"stdout","text":"Found 240 images belonging to 2 classes.\nFound 60 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"714b9fad0a214e4fb38ebe471cb89740","deepnote_cell_type":"text-cell-h2"},"source":"## Step 4: Build the CNN Model"},{"cell_type":"code","metadata":{"cell_id":"e20f31772f8045d08bdae07dcfddfab1","deepnote_cell_type":"code"},"source":"# Create the CNN model\nmodel = models.Sequential()\n\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Flatten())\n\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Display model summary\nmodel.summary()\n","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"82dfd21f769f42f4a36f057083eaebc9","deepnote_cell_type":"text-cell-h2"},"source":"## Step 5: Train the Model"},{"cell_type":"code","metadata":{"cell_id":"85315184e2034e3f8d3af472e5bd49a1","deepnote_cell_type":"code"},"source":"# Define the number of training and validation steps per epoch\ntrain_steps_per_epoch = train_generator.samples // batch_size\nval_steps_per_epoch = validation_generator.samples // batch_size\n\n# Set the number of training epochs\nepochs = 10\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_steps_per_epoch,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=val_steps_per_epoch\n)","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"75139406d5814457a28754e9c15b9b0c","deepnote_cell_type":"text-cell-h2"},"source":"## Step 6: Evaluate the Model"},{"cell_type":"code","metadata":{"source_hash":"ed088632","execution_start":1690257371196,"execution_millis":435,"deepnote_to_be_reexecuted":false,"cell_id":"63f9c82b435445a3aab0e90c4fae268d","deepnote_cell_type":"code"},"source":"# Evaluate the model on the test set\nloss, accuracy = model.evaluate(validation_generator, steps=val_steps_per_epoch)\nprint(f\"Validation Accuracy: {accuracy*100:.2f}%\")","execution_count":7,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn [7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(validation_generator, steps\u001b[38;5;241m=\u001b[39mval_steps_per_epoch)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"4f3ed87a1606478293276574a2579d23","deepnote_cell_type":"text-cell-h2"},"source":"## Step 7: Make Predictions"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"d909b5d212f2422baab5a789f1dacec7","deepnote_cell_type":"text-cell-p"},"source":"After training and evaluating the model, you can use it to make predictions on new images. Use the model.predict() function to obtain the prediction probabilities for each class. For instance:"},{"cell_type":"code","metadata":{"cell_id":"eeefc2f3aa7349df91cd4d74db42b836","deepnote_cell_type":"code"},"source":"# Assuming you have a new image (img) to predict\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Add batch dimension\n\n# Make the prediction\npredictions = model.predict(img_array)\nprobability = predictions[0][0]\n\n# Check if the image contains eyeglasses or not\nif probability > 0.5:\n    print(\"Eyeglasses detected!\")\nelse:\n    print(\"No eyeglasses detected.\")","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=dfa597de-6a5a-42f4-aeba-81801b5273f9' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"ab520d1832a448bb88de32954a62c0b5","deepnote_execution_queue":[]}}